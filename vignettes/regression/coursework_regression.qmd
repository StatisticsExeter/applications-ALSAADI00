---
title: "Understanding costs"
author: "Manal Alsaadi"
format: 
  html:
    math: mathjax
---

This report summarises the practical work I carried out to complete the regression workflow for analysing household energy costs and carbon emissions using the provided pipeline. Following my professor’s feedback, I begin by explaining **what the problem is**, **what data we use**, and **how I approached solving it**, before describing the implementation details and results.

## The problem

The broad aim of this coursework is to understand how household energy costs and carbon emissions vary across different parts of the UK, and in particular **how much of these differences are due to local authorities themselves** rather than simply differences in the types of properties they contain.

More precisely, we are interested in:

- measuring the **average energy shortfall or emissions shortfall** for properties, and  
- assessing whether some local authorities have systematically higher or lower shortfalls **after adjusting** for basic characteristics of the housing stock, such as the number of rooms and whether houses were built before or after 1930.

This naturally leads to a **multilevel regression problem**, where properties are nested within local authorities. We want a model that:

1. controls for property-level characteristics (age and number of rooms), and  
2. includes a **random effect for each local authority** to capture unexplained area-level differences.

The resulting local-authority random effects then provide an adjusted way to compare authorities in terms of energy performance.

## The data

The analysis uses data derived from the UK **Energy Performance Certificates (EPCs)**. Each EPC records information about a property’s energy performance, including estimated energy usage and emissions.

For this assignment, the raw database has already been processed into a **local-authority level dataset** stored as:

- `data_cache/la_energy.csv`

This dataset is created by the `task_energy_metrics_la` task in `dodo_regression.py`, which:

- runs the SQL query in `sql/la_energy.sql`,  
- uses the helper function `load_pg_data(QUERY)` to pull data from PostgreSQL,  
- drops rows with missing values, and  
- saves the cleaned result to CSV.

In the resulting dataset, the key variables used in the regression are:

- `shortfall`: a continuous outcome measuring the energy or emissions shortfall for each certificate,
- `n_rooms`: the number of heated rooms in the property,
- `age`: an age category (for example, pre-1930 vs post-1930),
- `local_authority_code`: an identifier for the local authority in which the property is located.

The modelling question is: **how much variation in `shortfall` is explained by `n_rooms` and `age`, and how much remains as systematic differences between local authorities?**

## How I solved the problem

I was given the following Python files as a partially completed pipeline:

- `eda.py`
- `fit_model.py`
- `caterpillar_reffs.py`
- the automation script `dodo_regression.py`

In addition, the data extraction step relies on an SQL query in `sql/la_energy.sql` and the helper function `load_pg_data` from the course utilities. My task was to ensure that these components work together to:

1. extract and cache the local-authority level energy data,  
2. generate exploratory boxplots,  
3. fit a mixed-effects regression model, and  
4. produce a caterpillar plot of local-authority random effects.

Once the code was implemented and debugged, I was able to run the entire workflow with:

```bash
doit -f dodo_regression.py
```

and obtain all intermediate data files, model summaries and HTML visualisations without errors.

```{python}
#| echo: false
import pandas as pd
import sys
import os
project_root = os.path.abspath("../..")
sys.path.append(project_root)
from course.utils import find_project_root

base_dir = find_project_root()
vignette_dir = base_dir / "data_cache" / "vignettes" / "regression"
```

## Exploratory data analysis

The first part of my work was to implement exploratory plots in `eda.py`. A small helper function `_boxplot` takes a DataFrame, an optional grouping variable and a response variable, and returns an interactive Plotly boxplot. This function is used by two functions:

- `boxplot_age()`: produces a boxplot of `shortfall` by `age` category,
- `boxplot_rooms()`: produces a boxplot of `shortfall` by `n_rooms`.

Both functions read `data_cache/la_energy.csv`, call `_boxplot`, and save the resulting HTML files into the regression vignette directory as:

- `boxplot_age.html`
- `boxplot_rooms.html`

The `task_eda` task in `dodo_regression.py` is then responsible for running these functions and ensuring the HTML outputs exist.

Below I embed the two boxplots produced by the workflow.

### Shortfall by age category

```{python}
#| echo: false
from IPython.display import IFrame

age_box_path = vignette_dir / "boxplot_age.html"
IFrame(src=str(age_box_path), width="100%", height=500)
```

### Shortfall by number of rooms

```{python}
#| echo: false
rooms_box_path = vignette_dir / "boxplot_rooms.html"
IFrame(src=str(rooms_box_path), width="100%", height=500)
```

These plots allow us to see how the distribution of `shortfall` changes across property age groups and by the number of heated rooms. In particular, they highlight both the typical shortfall (through the median) and the spread and presence of outliers in each group.

## Mixed-effects regression model

### Model specification

The main statistical model is implemented in `fit_model.py`. The function `_fit_model(df)` uses `statsmodels`’ `mixedlm` to fit a linear mixed-effects model with:

- response: `shortfall`,
- fixed effects: `n_rooms` and `age`,
- random intercept: one per `local_authority_code`.

In mathematical notation, for certificate \(i\) in local authority \(j\) the model can be written as:

$$
\text{shortfall}_{ij}
= \beta_0
+ \beta_1 \; \text{n\_rooms}_{ij}
+ \beta_2 \; \text{age}_{ij}
+ u_j
+ \varepsilon_{ij},
$$

where

- \(u_j \sim N(0, \tau^2)\) is the random intercept for local authority \(j\),
- \(\varepsilon_{ij} \sim N(0, \sigma^2)\) is the individual-level error term,
- \(\beta_0, \beta_1, \beta_2\) are the fixed-effect coefficients for the intercept, rooms and age respectively.

The function `fit_model()` reads `data_cache/la_energy.csv`, calls `_fit_model(df)`, and then:

1. extracts a tidy table of random effects using the helper `_random_effects(results)`,  
2. saves this table to `data_cache/models/reffs.csv`,  
3. writes a full text summary of the fitted model to `data_cache/vignettes/regression/model_fit.txt`.

The model is fitted using maximum likelihood (`reml=False`) with the `lbfgs` optimiser, which is a stable choice for this dataset.

### Model summary

The following code chunk prints the saved text summary of the fitted mixed-effects model:

```{python}
#| echo: false
#| results: 'asis'
model_summary_path = vignette_dir / "model_fit.txt"
with open(model_summary_path, "r", encoding="utf-8") as f:
    print(f.read())
```

From this summary we can read off the estimated coefficients for `n_rooms` and `age`, their standard errors, and associated \(z\)-statistics and \(p\)-values. The coefficient for `n_rooms` represents the expected change in shortfall when we increase the number of rooms by one, holding age and local authority constant. The coefficient for `age` compares the mean shortfall between age categories, again adjusting for the other variables and the random authority effect.

The variance component for the random intercept shows how much variation in shortfall is attributable to differences between local authorities after controlling for rooms and age.

## Random effects and ranking local authorities

The core task in this coursework is to assess how local authorities differ once we account for the age and size of properties in their area. This is captured by the random intercepts \(u_j\).

In `fit_model.py`, I implemented `_random_effects(results)` to:

- convert the dictionary of random effects from `statsmodels` into a tidy `DataFrame`,  
- ensure that the main column is named `Intercept`,  
- add the local-authority identifier as a `group` column,  
- construct 95% confidence intervals for each random effect using the estimated random-effect variance (via `cov_re`),  
- sort the results by the intercept value for easier plotting.

The resulting CSV `reffs.csv` contains one row per local authority, with columns:

- `Intercept`: estimated random intercept \(\hat{u}_j\),  
- `group`: local authority code,  
- `lower`, `upper`: lower and upper bounds of the 95% confidence interval for \(\hat{u}_j\).

To visualise these random effects, I wrote `plot_caterpillar()` in `caterpillar_reffs.py`. This function:

1. reads `data_cache/models/reffs.csv`,  
2. uses Plotly to create a caterpillar plot where each authority is a horizontal line with its confidence interval and point estimate,  
3. adds a vertical reference line at zero (the “average” authority),  
4. writes the interactive plot to `data_cache/vignettes/regression/caterpillar.html`.

The corresponding `task_caterpillar_plot` in `dodo_regression.py` ensures that this plot is generated after the model has been fitted.

```{python}
#| echo: false
from IPython.display import IFrame

caterpillar_path = vignette_dir / "caterpillar.html"
IFrame(src=str(caterpillar_path), width="100%", height=500)
```

Authorities with random intercepts clearly above zero can be interpreted as having larger-than-average shortfalls, even after adjusting for property age and number of rooms. Conversely, authorities with random effects well below zero appear to perform better than average in terms of energy cost or emissions shortfall.

## Extension for extra credit: residual diagnostics

As an extension, I added a simple **residual diagnostics** step to `fit_model.py`. After fitting the mixed-effects model, I now compute the residuals and fitted values and create an interactive residuals–versus–fitted plot using Plotly. The resulting HTML file is saved in the same vignette directory as the other regression outputs.

### Residuals vs fitted values

```{python}
#| echo: false
from IPython.display import IFrame

resid_vs_fitted_path = vignette_dir / "residuals_vs_fitted.html"
IFrame(src=str(resid_vs_fitted_path), width="100%", height=500)
```

This plot helps assess whether the model assumptions are reasonable. Ideally, residuals should be scattered roughly symmetrically around zero with no obvious pattern. Any funnel shape, curvature or strong structure would suggest heteroscedasticity or model misspecification.

## Putting the pipeline together

Overall, my work on this coursework consisted of:

- implementing the EDA plotting functions and ensuring their outputs are saved in the correct vignette directory,  
- specifying and fitting the mixed-effects regression model with a random intercept per local authority,  
- extracting the random effects and constructing confidence intervals in a tidy format suitable for plotting,  
- building an interactive caterpillar plot that ranks local authorities by their adjusted performance,  
- adding a residual diagnostics plot as an extension to check model assumptions,  
- wiring these components into the `doit` automation script so that a single command runs the full workflow from data extraction to visualisation.

With these pieces in place, the `doit` run completes successfully, generating both numerical summaries and visual outputs that answer the original question: **which local authorities appear to have higher or lower energy shortfalls once we control for property age and size?**


## Record of AI use for MTHM503 Regression coursework

Instructions: You can use this document to record when, how and why you used GenAI to complete your assessment. It will help you create a record of AI use to submit alongside your references for AI-integrated and AI-assisted assignments. It may also be useful to help you discuss your AI use if you are required to do so in an academic conduct meeting.

| **Date**       | **AI tool used** | **Purpose**                                | **Prompt**                                 | **Hyperlink to output (where possible)** | **Section of work used for** |
|----------------|------------------|--------------------------------------------|--------------------------------------------|------------------------------------------|-------------------------------|
| 08/12/2025     | ChatGPT          | To suggest simple extensions to my regression pipeline and help design a residual diagnostics plot | "I need to extend this regression pipeline, please suggest some easy extensions" |  | Extension: residual diagnostics |
