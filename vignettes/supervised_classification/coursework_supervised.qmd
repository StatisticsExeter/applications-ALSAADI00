---
title: "Building a classifier to predicting house age"
author: "Manal Alsaadi"
format: html
---

This report summarises the practical work I carried out to run and complete the supervised learning workflow using the provided pipeline. The focus is on the tasks I completed, the additional classifier I implemented, and the results produced by the full pipeline.

I was given the following Python files as a partially completed pipeline:

- `split.py`, `split_test_train.py`
- `eda.py`
- `metrics.py`
- `classify.py`
- `predict.py`
- `roc_curve.py`
- the automation script `dodo_supervised.py`

All functions were already defined, and my task was to run the full workflow using:

```bash
doit -f dodo_supervised.py
```

When first running this command, the execution halted due to syntax errors in several of the provided files. I inspected and corrected these issues so that the tasks could run sequentially.

After resolving the syntax errors, I encountered a persistent failure related to the ROC curve task:  
`roc_curve.py` was searching for a file named `*_y_pred_prob.csv`, which did not exist. This indicated that the pipeline expected probability predictions, but the existing `predict.py` only output class labels, not probabilities.

To fix this, I updated:

- `predict.py` — adding functionality to generate and save prediction probabilities.
- `roc_curve.py` — ensuring it pointed to the correct probability files rather than class-label CSVs.

As an extension for additional credit, I also:

- implemented a **logistic regression** classifier in `classify.py`,
- added prediction support for this model in `predict.py`,
- added a metrics task in `metrics.py` and `dodo_supervised.py`, and
- updated the ROC plotting code so that LDA, QDA and logistic regression are all shown on the same curve.

Once these adjustments were made, the pipeline successfully produced:

- the train/test splits  
- EDA outputs  
- LDA, QDA and logistic regression metric tables  
- the ROC curve HTML visualisation  

and the entire `doit` run completed without errors.

Data on UK Energy Certificates provide information on a wide range of energy-related metrics. For this assessment, the task was to classify whether a house was built before or after 1930 using seven available predictors.

## Exploratory data analysis

```{python}
#| echo: false
import pandas as pd
import sys
import os
project_root =os.path.abspath("../..")
sys.path.append(project_root)
from course.utils import find_project_root

base_dir = find_project_root()
vignette_dir = base_dir / "data_cache" / "vignettes" / "supervised_classification"
```

The dataset contains certificates that have been labelled as pre-1930 or post-1930. Below I show simple frequency information for the outcome variable and basic group summaries for the key predictors used in the classifiers.

```{python}
#| echo: false
#| results: 'asis'
freq_path = vignette_dir / "frequencies.csv"
df = pd.read_csv(freq_path)
print(df.round(3).to_markdown(index=False))
```

```{python}
#| echo: false
#| results: 'asis'
grouped_path = vignette_dir / "grouped_stats.csv"
df = pd.read_csv(grouped_path)
print(df.round(3).to_markdown(index=False))
```

A scatterplot of two of the key variables, coloured by whether the property was built before or after 1930, helps to visualise the separation achieved by these features.

```{python}
#| echo: false
from IPython.display import IFrame

scatter_path = vignette_dir / "scatterplot.html"
IFrame(src=str(scatter_path), width="100%", height=500)
```

## Fitting LDA, QDA and logistic regression classifiers

The workflow produced summary statistics for all three classifiers. These tables report metrics such as precision, recall and F1-score for each class, as well as overall accuracy.

### LDA metrics

```{python}
#| echo: false
#| results: 'asis'
lda_path = vignette_dir / "lda.csv"
df = pd.read_csv(lda_path)
df.rename(columns={"Unnamed: 0": "Category"}, inplace=True)
print(df.round(3).to_markdown(index=False))
```

### QDA metrics

```{python}
#| echo: false
#| results: 'asis'
qda_path = vignette_dir / "qda.csv"
df = pd.read_csv(qda_path)
df.rename(columns={"Unnamed: 0": "Category"}, inplace=True)
print(df.round(3).to_markdown(index=False))
```

### Logistic regression metrics

```{python}
#| echo: false
#| results: 'asis'
logreg_path = vignette_dir / "logreg.csv"
df = pd.read_csv(logreg_path)
df.rename(columns={"Unnamed: 0": "Category"}, inplace=True)
print(df.round(3).to_markdown(index=False))
```

Taken together, these results show how each classifier balances performance across the two age groups. By examining the class-specific precision, recall and F1-scores in the tables above, we can see whether any one method consistently outperforms the others or whether performance is broadly similar across LDA, QDA and logistic regression.

## ROC curve (and AUC) for three classifiers

The final part of the workflow produces an ROC curve comparing the three classifiers on the same test set, along with their AUC values.

```{python}
#| echo: false
from IPython.display import IFrame

roc_path = vignette_dir / "roc.html"
IFrame(src=str(roc_path), width="100%", height=500)
```

The ROC curve allows us to compare the trade-off between true positive rate and false positive rate for LDA, QDA and logistic regression over all possible classification thresholds. The corresponding AUC values summarise overall discrimination ability in a single number for each model. This provides a convenient way to assess which classifier performs best in terms of ranking properties by the probability of belonging to the pre-1930 group.

## Record of AI use for MTHM503 supervised coursework

| **Date**       | **AI tool used** | **Purpose**                                | **Prompt**                                 | **Hyperlink to output (where possible)** | **Section of work used for** |
|----------------|------------------|--------------------------------------------|--------------------------------------------|------------------------------------------|-------------------------------|
| 01/12/2025     | ChatGPT          | Troubleshooting missing `y_pred_prob.csv` issue; verifying that the fix required modifying `predict.py` and `roc_curve.py` | "The python files are connected. I am getting error in roc_curve.py in y_pred_prob_path and my suspicion is that it is based on some behavior which should be exhibited by the predict.py file but is missing. Please help." | *N/A* | Fixing probability-output stage of the pipeline |

