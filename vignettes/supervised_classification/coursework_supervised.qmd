---
title: "Building a classifier to predict house age"
author: "Manal Alsaadi"
format: html
---

This report summarises the practical work I carried out to complete the supervised learning workflow using the provided pipeline. Following my professor’s feedback, I begin by clearly describing **the problem**, **the data**, and **how I approached solving it**, before detailing the implementation steps and results.

## The problem

The goal of this coursework is to build a supervised learning model that can **predict whether a house was built before or after 1930**, using features extracted from UK Energy Performance Certificates (EPCs). EPCs contain rich information about properties—including size, insulation, heating systems and energy efficiency—and these features allow us to distinguish older housing stock from more modern properties.

This is a **binary classification problem**, where the response variable is:

- `age_pre_1930` = 1 if the property was built before 1930  
- `age_pre_1930` = 0 if the property was built after 1930

The task involves fitting multiple classifiers, examining their behaviour, and comparing their predictive performance.

## The data

The dataset supplied to us is a cleaned subset of the UK EPC database. It includes:

- thousands of labelled EPC records,
- seven predictor variables used for classification (e.g., floor area, energy cost, energy efficiency rating),
- the binary age indicator described above.

These variables were saved in the pipeline's data cache, with scripts provided to split the data and generate exploratory summaries.

Because EPC data covers a wide range of building types and ages, the predictors show meaningful differences between pre‑1930 and post‑1930 houses—ideal for building statistical classifiers.

## How I solved the problem

The supervised learning workflow was provided as a partially completed pipeline consisting of:

- `split.py`, `split_test_train.py`
- `eda.py`
- `metrics.py`
- `classify.py`
- `predict.py`
- `roc_curve.py`
- and the automation script `dodo_supervised.py`.

My task was to:

1. **debug and repair the pipeline**, so that all tasks execute in order;  
2. **implement missing functionality**, especially probability predictions for ROC curves;  
3. **extend the workflow** by adding logistic regression and ensuring the pipeline compared all three classifiers.

I began by running:

```bash
doit -f dodo_supervised.py
```

This immediately produced syntax errors in multiple files. After fixing these, the pipeline progressed until the ROC step failed because the expected probability prediction file `*_y_pred_prob.csv` did not exist. The `predict.py` script produced **only class labels**, but ROC curves require **probability scores**.

### Fixes implemented

To resolve this, I made several key changes:

- **Updated `predict.py`** to compute probability predictions (`predict_proba`) and save them correctly.
- **Updated `roc_curve.py`** so it reads the new probability files and produces correct ROC curves.
- **Added logistic regression** in `classify.py` for additional credit.
- **Added logistic regression prediction support** in `predict.py`.
- **Updated `metrics.py` and the `dodo_supervised.py` orchestration**, enabling metrics to be computed for all models.
- **Extended the ROC plotting code** so LDA, QDA and logistic regression all appear on one plot.

After these changes, running the workflow produced all expected outputs without errors.

## Exploratory data analysis

```{python}
#| echo: false
import pandas as pd
import sys
import os
project_root = os.path.abspath("../..")
sys.path.append(project_root)
from course.utils import find_project_root

base_dir = find_project_root()
vignette_dir = base_dir / "data_cache" / "vignettes" / "supervised_classification"
```

Before fitting any models, I summarised class frequencies and explored the distribution of predictors.

### Class frequencies

```{python}
#| echo: false
#| results: 'asis'
freq_path = vignette_dir / "frequencies.csv"
df = pd.read_csv(freq_path)
print(df.round(3).to_markdown(index=False))
```

### Summary statistics by age group

```{python}
#| echo: false
#| results: 'asis'
grouped_path = vignette_dir / "grouped_stats.csv"
df = pd.read_csv(grouped_path)
print(df.round(3).to_markdown(index=False))
```

### Scatterplot of two predictors

```{python}
#| echo: false
from IPython.display import IFrame

scatter_path = vignette_dir / "scatterplot.html"
IFrame(src=str(scatter_path), width="100%", height=500)
```

This plot helps us visualise whether any separation between age groups is visible in the raw features.

## Fitting LDA, QDA and logistic regression classifiers

The pipeline then fits three models:

- **Linear Discriminant Analysis (LDA)**
- **Quadratic Discriminant Analysis (QDA)**
- **Logistic Regression**

For each model, the workflow computes accuracy, precision, recall and F1-score.

### LDA metrics

```{python}
#| echo: false
#| results: 'asis'
lda_path = vignette_dir / "lda.csv"
df = pd.read_csv(lda_path)
df.rename(columns={"Unnamed: 0": "Category"}, inplace=True)
print(df.round(3).to_markdown(index=False))
```

### QDA metrics

```{python}
#| echo: false
#| results: 'asis'
qda_path = vignette_dir / "qda.csv"
df = pd.read_csv(qda_path)
df.rename(columns={"Unnamed: 0": "Category"}, inplace=True)
print(df.round(3).to_markdown(index=False))
```

### Logistic regression metrics

```{python}
#| echo: false
#| results: 'asis'
logreg_path = vignette_dir / "logreg.csv"
df = pd.read_csv(logreg_path)
df.rename(columns={"Unnamed: 0": "Category"}, inplace=True)
print(df.round(3).to_markdown(index=False))
```

These tables highlight how each classifier performs across the two age groups, revealing strengths and weaknesses in identifying older houses.

## ROC curve and AUC for all classifiers

Finally, I produced an ROC curve that overlays all three models for comparison.

```{python}
#| echo: false
from IPython.display import IFrame

roc_path = vignette_dir / "roc.html"
IFrame(src=str(roc_path), width="100%", height=500)
```

The ROC curve, together with the area under the curve (AUC), shows how effectively each model distinguishes pre‑1930 from post‑1930 houses across all thresholds.

## Record of AI use for MTHM503 supervised coursework

| **Date**       | **AI tool used** | **Purpose**                                | **Prompt**                                 | **Hyperlink to output (where possible)** | **Section of work used for** |
|----------------|------------------|--------------------------------------------|--------------------------------------------|------------------------------------------|-------------------------------|
| 01/12/2025     | ChatGPT          | Troubleshooting missing `y_pred_prob.csv` and updating pipeline components | "What is the issue with below roc_curve function?" | *N/A* | Fixing prediction‑probability stage |
